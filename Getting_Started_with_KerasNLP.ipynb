{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kerriea-star/KerasNLP/blob/main/Getting_Started_with_KerasNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbS4sRVCPb-W"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "KerasNLP is a natural language processing library that supports users through their entire development cycle. Our workflows are built from modular components that have state-of-the-art preset weights and architectures when used out-of-the-box and are easily customizable when more control is needed.\n",
        "\n",
        "This library is an extension of the core Keras API; all high-level modules are Layers or Models.\n",
        "\n",
        "KerasNLP uses the **Keras Core** library to work with any of TensorFlow, Pytorch and Jax. In the guide below, we will use the `jax` backend for training our models, and `tf.data` for efficiently running our input preprocessing. But feel free to mix things up! This guide runs in TensorFlow or PyTorch backends with zero changes, simply update the `KERAS_BACKEND` below.\n",
        "\n",
        "\n",
        "Search Keras documentation...\n",
        "\n",
        "» Developer guides / KerasNLP / Getting Started with KerasNLP\n",
        "Getting Started with KerasNLP\n",
        "Author: Jonathan Bischof\n",
        "Date created: 2022/12/15\n",
        "Last modified: 2023/07/01\n",
        "Description: An introduction to the KerasNLP API.\n",
        "\n",
        " View in Colab • GitHub source\n",
        "\n",
        "Introduction\n",
        "KerasNLP is a natural language processing library that supports users through their entire development cycle. Our workflows are built from modular components that have state-of-the-art preset weights and architectures when used out-of-the-box and are easily customizable when more control is needed.\n",
        "\n",
        "This library is an extension of the core Keras API; all high-level modules are Layers or Models. If you are familiar with Keras, congratulations! You already understand most of KerasNLP.\n",
        "\n",
        "KerasNLP uses the Keras Core library to work with any of TensorFlow, Pytorch and Jax. In the guide below, we will use the jax backend for training our models, and tf.data for efficiently running our input preprocessing. But feel free to mix things up! This guide runs in TensorFlow or PyTorch backends with zero changes, simply update the KERAS_BACKEND below.\n",
        "\n",
        "This guide demonstrates our modular approach using a sentiment analysis example at six levels of complexity:\n",
        "\n",
        "*   Inference with a pretrained classifier\n",
        "\n",
        "*   Fine tuning a pretrained backbone\n",
        "*   Fine tuning with user-controlled preprocessing\n",
        "*   Fine tuning a custom model\n",
        "*   Pretraining a backbone model\n",
        "*   LBuild and train your own transformer from scratch\n",
        "\n",
        "Throughout our guide, we use Professor Keras, the official Keras mascot, as a visual\n",
        "reference for the complexity of the material:\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/keras-nlp/getting_started_guide/prof_keras_evolution.png\" alt=\"drawing\" height=\"250\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UAMIN0sOpa1",
        "outputId": "e790c4d3-3823-4325-e740-9f79da38629c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.1/590.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade keras-nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3AU5RFkRjRW",
        "outputId": "67b22f63-336b-40d2-bace-402f6e9c7ffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using JAX backend.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\" # or \"tensorflow\" or \"torch\"\n",
        "\n",
        "import keras_nlp\n",
        "import keras_core as keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjaMHJ1KVZou"
      },
      "source": [
        "## API quickstart\n",
        "\n",
        "Our highest level API is `keras_nlp.models`. These symbols cover the complete user\n",
        "journey of converting strings to tokens, tokens to dense features, and dense features to\n",
        "task-specific output. For each `XX` architecture (e.g., `Bert`), we offer the following\n",
        "modules:\n",
        "\n",
        "* **Tokenizer**: `keras_nlp.models.XXTokenizer`\n",
        "  * **What it does**: Converts strings to sequences of token ids.\n",
        "  * **Why it's important**: The raw bytes of a string are too high dimensional to be useful\n",
        "    features so we first map them to a small number of tokens, for example `\"The quick brown\n",
        "    fox\"` to `[\"the\", \"qu\", \"##ick\", \"br\", \"##own\", \"fox\"]`.\n",
        "  * **Inherits from**: `keras.layers.Layer`.\n",
        "* **Preprocessor**: `keras_nlp.models.XXPreprocessor`\n",
        "  * **What it does**: Converts strings to a dictionary of preprocessed tensors consumed by\n",
        "    the backbone, starting with tokenization.\n",
        "  * **Why it's important**: Each model uses special tokens and extra tensors to understand\n",
        "    the input such as delimiting input segments and identifying padding tokens. Padding each\n",
        "    sequence to the same length improves computational efficiency.\n",
        "  * **Has a**: `XXTokenizer`.\n",
        "  * **Inherits from**: `keras.layers.Layer`.\n",
        "* **Backbone**: `keras_nlp.models.XXBackbone`\n",
        "  * **What it does**: Converts preprocessed tensors to dense features. *Does not handle\n",
        "    strings; call the preprocessor first.*\n",
        "  * **Why it's important**: The backbone distills the input tokens into dense features that\n",
        "    can be used in downstream tasks. It is generally pretrained on a language modeling task\n",
        "    using massive amounts of unlabeled data. Transferring this information to a new task is a\n",
        "    major breakthrough in modern NLP.\n",
        "  * **Inherits from**: `keras.Model`.\n",
        "* **Task**: e.g., `keras_nlp.models.XXClassifier`\n",
        "  * **What it does**: Converts strings to task-specific output (e.g., classification\n",
        "    probabilities).\n",
        "  * **Why it's important**: Task models combine string preprocessing and the backbone model\n",
        "    with task-specific `Layers` to solve a problem such as sentence classification, token\n",
        "    classification, or text generation. The additional `Layers` must be fine-tuned on labeled\n",
        "    data.\n",
        "  * **Has a**: `XXBackbone` and `XXPreprocessor`.\n",
        "  * **Inherits from**: `keras.Model`.\n",
        "\n",
        "Here is the modular hierarchy for `BertClassifier` (all relationships are compositional):\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/keras-nlp/getting_started_guide/class_diagram.png\" alt=\"drawing\" height=\"300\"/>\n",
        "\n",
        "All modules can be used independently and have a `from_preset()` method in addition to\n",
        "the standard constructor that instantiates the class with **preset** architecture and\n",
        "weights (see examples below)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3ce_k03Vo13"
      },
      "source": [
        "## Data\n",
        "We will use a running example of sentiment analysis of IMDB movie reviews. In this task, we use the text to predict whether the review was positive (`label = 1`) or negative (`label = 0`).\n",
        "\n",
        "We load the data using `keras.utils.text_dataset_from_directory`, which utilizes the powerful `tf.data.Dataset` format for examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pe6Fqg0S3X2",
        "outputId": "dbb1f4b5-a973-4c41-9957-cc175d7dafee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  46.6M      0  0:00:01  0:00:01 --:--:-- 46.6M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz\n",
        "!# Remove unsupervised examples\n",
        "!rm -r aclImdb/train/unsup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em4zitA9V_aH",
        "outputId": "9333f527-f52a-48b5-ed6b-106139dacf5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "(<tf.Tensor: shape=(), dtype=string, numpy=b\"I very much looked forward to this movie. Its a good family movie; however, if Michael Landon Jr.'s editing team did a better job of editing, the movie would be much better. Too many scenes out of context. I do hope there is another movie from the series, they're all very good. But, if another one is made, I beg them to take better care at editing. This story was all over the place and didn't seem to have a center. Which is unfortunate because the other movies of the series were great. I enjoy the story of Willie and Missy; they're both great role models. Plus, the romantic side of the viewers always enjoy a good love story.\">, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 16\n",
        "imdb_train = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size = BATCH_SIZE,\n",
        ")\n",
        "imdb_test = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\",\n",
        "    batch_size = BATCH_SIZE,\n",
        ")\n",
        "\n",
        "# Inspec first review\n",
        "# Format is (review text tensor, label tensor)\n",
        "\n",
        "print(imdb_train.unbatch().take(1).get_single_element())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGq8KHlpYdZ-"
      },
      "source": [
        "## Inference with a pretrained classifier\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/keras-nlp/getting_started_guide/prof_keras_beginner.png\" alt=\"drawing\" height=\"250\"/>\n",
        "\n",
        "The highest level module in KerasNLP is a **task**. A **task** is a `keras.Model`\n",
        "consisting of a (generally pretrained) **backbone** model and task-specific layers.\n",
        "Here's an example using `keras_nlp.models.BertClassifier`.\n",
        "\n",
        "**Note**: Outputs are the logits per class (e.g., `[0, 0]` is 50% chance of positive). The output is\n",
        "[negative, positive] for binary classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGF3TRdcWwRH",
        "outputId": "82e35bd3-23d3-496d-a7d2-a567d31b2914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/bert_tiny_en_uncased_sst2/v1/vocab.txt\n",
            "\u001b[1m231508/231508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step       \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/bert_tiny_en_uncased_sst2/v1/model.h5\n",
            "\u001b[1m17596448/17596448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.5387032,  1.5418268]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "classifier = keras_nlp.models.BertClassifier.from_preset(\"bert_tiny_en_uncased_sst2\")\n",
        "# Note: batched inputs expected so must wrap string in iterable\n",
        "classifier.predict([\"I love modular workflows in keras-nlp!\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wcY7xHsZt4o"
      },
      "source": [
        "All tasks have a `from_preset` method that constructs a `keras.Model` instance with preset preprocessing, architecture and weights. This means that we can pass raw strings in any format accepted by a `keras.Model` and get output specific to our task.\n",
        "\n",
        "This particular preset is a `\"bert_tiny_uncased_en\"` backbone fine-tuned on `sst2`, another movie review sentiment analysis (this time from Rotten Tomatoes). We use the `tiny` architecture for demo purposes, but larger models are recommended for SoTA performance.\n",
        "\n",
        "Let's evaluate our classifier on the IMDB dataset. You will note we don't need to call `keras.Model.compile` here. All task models like `BertClassifier` ship with compilation defaults, meaning we can just call `keras.Model.evaluate` directly. You can always call compile as normal to override these defaults (e.g. to add new metrics).\n",
        "\n",
        "The output below is [loss, accuracy],"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-PmlV16Y9G3",
        "outputId": "41c94258-e238-4ce8-b1f8-9e9ac624dde1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m683s\u001b[0m 435ms/step - loss: 0.4666 - sparse_categorical_accuracy: 0.7821\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4629073441028595, 0.783519983291626]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "classifier.evaluate(imdb_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine tuning a pretrained BERT backbone\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/keras-nlp/getting_started_guide/prof_keras_intermediate.png\" alt=\"drawing\" height=\"250\"/>\n",
        "\n",
        "When labeled text specific to our task is available, fine-tuning a custom classifier can\n",
        "improve performance. If we want to predict IMDB review sentiment, using IMDB data should\n",
        "perform better than Rotten Tomatoes data! And for many tasks, no relevant pretrained model\n",
        "will be available (e.g., categorizing customer reviews).\n",
        "\n",
        "The workflow for fine-tuning is almost identical to above, except that we request a\n",
        "**preset** for the **backbone**-only model rather than the entire classifier. When passed\n",
        "a **backbone** **preset**, a **task** `Model` will randomly initialize all task-specific\n",
        "layers in preparation for training. For all the **backbone** presets available for\n",
        "`BertClassifier`.\n",
        "\n",
        "To train your classifier, use `keras.Model.fit` as with any other\n",
        "`keras.Model`. As with our inference example, we can rely on the compilation\n",
        "defaults for the **task** and skip `keras.Model.compile`. As preprocessing is\n",
        "included, we again pass the raw data."
      ],
      "metadata": {
        "id": "hKfUJ2021YdP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXCKf-uoamDO",
        "outputId": "f6dea142-9d47-4516-d7c1-88bb9d76ba25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/bert_tiny_en_uncased/v1/vocab.txt\n",
            "\u001b[1m231508/231508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step       \n",
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/bert_tiny_en_uncased/v1/model.h5\n",
            "\u001b[1m17602216/17602216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3099s\u001b[0m 2s/step - loss: 0.5275 - sparse_categorical_accuracy: 0.7170 - val_loss: 0.3016 - val_sparse_categorical_accuracy: 0.8728\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras_core.src.callbacks.history.History at 0x7aadaf924be0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "classifier = keras_nlp.models.BertClassifier.from_preset(\n",
        "    \"bert_tiny_en_uncased\",\n",
        "    num_classes = 2,\n",
        ")\n",
        "classifier.fit(\n",
        "    imdb_train,\n",
        "    validation_data=imdb_test,\n",
        "    epochs=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see a significant lift in validation accuracy (0.78 -> 0.87) with a single epoch of training even though the IMDB dataset is much smaller than `sst2`."
      ],
      "metadata": {
        "id": "J4UjwZXjCkHM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3hX-HSEt1vkk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgzAnTjxeoTV9IDe6lQmZB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}